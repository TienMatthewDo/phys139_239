\newif\ifshowsolutions
\showsolutionsfalse
\input{../common/preamble}

\chead{
  {\vbox{
      \vspace{2mm}
      \large
      Machine Learning in Physics \hfill
      UCSD PHYS 139/239 \hfill \\[1pt]
      Homework 2\hfill
      Draft version due: Friday, April 26, 2024, 8:00pm\\
	  \hfill
	  Final version due: Wednesday, May 1, 2024, 5:00pm\\
    }
  }
}

\begin{document}
\pagestyle{fancy}

\section*{Policies}
\begin{itemize}
	\item You are free to collaborate on all of the problems, subject to the collaboration policy stated in the syllabus.
	\item Please submit your report as a single .pdf file to Gradescope under ``Homework 1" or ``Homework 1 Corrections".
	      \textbf{In the report, include any images generated by your code along with your answers to the questions.}
	      For instructions specifically pertaining to the Gradescope submission process, see \url{https://www.gradescope.com/get_started#student-submission}.
	\item Please submit your code as a .zip archive to Gradescope under ``Homework 1 Code'' or ``Homework 1 Code Corrections".
	      The .zip file should contain your code files.
	      Submit your code either as Jupyter notebook .ipynb files or .py files.
\end{itemize}

\newpage
\section{Stochastic Gradient Descent [36 Points]}
% \materials{lecture 2}

Stochastic gradient descent (SGD) is an important optimization method in machine learning, used everywhere from logistic regression to training neural networks.
In this problem, you will be asked to first implement SGD for linear regression using the squared loss function.
Then, you will analyze how several parameters affect the learning process.

Linear regression learns a model of the form:
\begin{align*}
	f(x_1, x_2, \cdots, x_d) = \left(\sum_{i=1}^d w_i x_i\right) + b
\end{align*}

% problem A tests the students understanding of matrix representations and serves are a reminder that the bias term is still there.
\begin{problem}[2]
We can make our algebra and coding simpler by writing $f(x_1, x_2, \cdots, x_d) = \mathbf{w}^\intercal\mathbf{x}$ for vectors $\mathbf{w}$ and $\mathbf{x}$.
But at first glance, this formulation seems to be missing the bias term $b$ from the equation above.
How should we define $\mathbf{x}$ and $\mathbf{w}$ such that the model includes the bias term?
\end{problem}
\begin{hint}
	Include an additional element in $\mathbf{w}$ and $\mathbf{x}$.
\end{hint}
\begin{solution}

\end{solution}

Linear regression learns a model by minimizing the squared loss function $L$, which is the sum across all training data $\{(\mathbf{x}_1, y_1),\cdots,(\mathbf{x}_N, y_N)\}$ of the squared difference between actual and predicted output values:
\begin{equation}
	L(f) = \sum_{i=1}^N (y_i - \mathbf{w}^\intercal\mathbf{x}_i)^2
\end{equation}

\begin{problem}[2]
SGD uses the gradient of the loss function to make incremental adjustments to the weight vector $\mathbf{w}$.
Derive the gradient of the squared loss function with respect to $\mathbf{w}$ for linear regression.
\end{problem}
\begin{solution}

\end{solution}

The following few problems ask you to work with the first of two provided Jupyter notebooks for this problem, \texttt{1_notebook_part1.ipynb}, which includes tools for gradient descent visualization.
This notebook utilizes the files \texttt{sgd_helper.py} and \texttt{sgd_multiopt_helper.py}, but you should not need to modify either of these files.

\newpage

For your implementation of problems C--E, \textbf{do not} consider the bias term.

\begin{problem}[8]
Implement the \texttt{loss}, \texttt{gradient}, and \texttt{SGD} functions, defined in the notebook, to perform SGD, using the guidelines below:

\begin{itemize}
	\item Use a squared loss function.
	\item Terminate the SGD process after a specified number of \emph{epochs}.
	      Each epoch corresponds to one full pass over the entire dataset.
	      One SGD iteration (weight update) is performed for each point in the dataset.
	      So one epoch is equivalent to $N$ gradient updates, where $N$ is the size of the dataset.
	\item It is recommended, but not required, that you shuffle the order of the points before each epoch such that you go through the points in a random order.
	      You can use \texttt{numpy.random.permutation}.
	\item Measure the loss after each epoch.
	      Your \texttt{SGD} function should output a vector with the loss after each epoch, and a matrix of the weights after each epoch (one row per epoch).
	      Note that the weights from all epochs are stored in order to run subsequent visualization code to illustrate SGD.
\end{itemize}
\end{problem}
\begin{solution}

\end{solution}

\begin{problem}[2]
Run the visualization code in the notebook corresponding to problem D.
How does the convergence behavior of SGD change as the starting point varies?
How does this differ between datasets 1 and 2?
Please answer in 2--3 sentences.
\end{problem}
\begin{solution}

\end{solution}

\begin{problem}[6]
Run the visualization code in the notebook corresponding to problem E.
One of the cells---titled ``Plotting SGD Convergence"---must be filled in as follows.
Perform SGD on dataset 1 for each of the learning rates $\eta \in \{10^{-6}, 5\times10^{-6}, 10^{-5}, 3\times 10^{-5}, 10^{-4}\}$.
On a single plot, show the training error vs. number of epochs trained for each of these values of $\eta$.
What happens as $\eta$ changes?
\end{problem}

\begin{solution}

\end{solution}


The following problems consider SGD with the larger, higher-dimensional dataset, \texttt{sgd_data.csv}.
The file has a header denoting which columns correspond to which values.
For these problems, use the Jupyter notebook \texttt{1_notebook_part2.ipynb}.

For your implementation of problems F--H, \textbf{do} consider the bias term using your answer to problem A.

\begin{problem}[6]
Use your SGD code with the given dataset, and report your final weights.
Follow the guidelines below for your implementation:

\begin{itemize}
	\item Use $\eta = e^{-15}$ as the step size.
	\item Use $\mathbf{w} = [0.001, 0.001, 0.001, 0.001]$ as the initial weight vector and $b = 0.001$ as the initial bias.
	\item Use at least 800 epochs.
	\item You should incorporate the bias term in your implementation of SGD and do so in the vector style of problem A.
	\item Note that for these problems, it is no longer necessary for the \texttt{SGD} function to store the weights after all epochs; you may change your code to only return the final weights.
\end{itemize}
%$\epsilon$ here is a measure of how much change in error there is compared to the initial error in the epoch. Calculate the change in error every epoch and compare it to the change in error from the first epoch. If new change/initial change is less than $\epsilon$, stop the training. $\eta$ is the factor by which you multiply the gradient in each step of the descent, and $\mathbf{w}$ is the initial weight vector.
\end{problem}
\begin{solution}
\end{solution}

\begin{problem}[2]
Perform SGD as in the previous problem for each learning rate $\eta$ in \[\{e^{-10}, e^{-11}, e^{-12}, e^{-13}, e^{-14}, e^{-15}\},\] and calculate the training error at the beginning of each epoch during training.
On a single plot, show training error vs. number of epochs trained for each of these values of $\eta$.
Explain what is happening.
\end{problem}
\begin{solution}

\end{solution}


\begin{problem}[2]
The closed form solution for linear regression with least squares is \[\mathbf{w} = \left(\sum_{i=1}^N \mathbf{x_i}\mathbf{x_i}^\intercal\right)^{-1}\left(\sum_{i=1}^N \mathbf{x_i}y_i\right).\]
Compute this analytical solution.
Does the result match up with what you got from SGD?
\end{problem}
\begin{solution}

\end{solution}

Answer the remaining questions in 1--2 short sentences.

\begin{problem}[2]
Is there any reason to use SGD when a closed form solution exists?
\end{problem}
\begin{solution}

\end{solution}

\begin{problem}[2]
Based on the SGD convergence plots that you generated earlier, describe a stopping condition that is more sophisticated than a pre-defined number of epochs.
\end{problem}
\begin{solution}

\end{solution}

\begin{problem}[2]
How does the convergence behavior of the weight vector differ between the perceptron and SGD algorithms?
\end{problem}
\begin{solution}
\end{solution}


\section{Neural networks vs. boosted decision trees [45 Points]}
% \materials{lectures 4--6}

In this problem, you will compare the performance of neural networks and boosted decision trees for binary classfication on a tabular dataset, namely the MiniBooNE dataset: \url{https://archive.ics.uci.edu/ml/datasets/MiniBooNE+particle+identification}.

This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background)
The dataset contains 130,065 samples with 50 features and a single binary label.
We will randomly split the dataset into training (80\%) and testing (20\%) subsets.

We will use \texttt{2_notebook_part1.ipynb} for parts A and B and \texttt{2_notebook_part1.ipynb} for parts C, D, and E.

\begin{problem}[15]
Using the MiniBooNE dataset and XGBoost, train a boosted decision tree on the training dataet.
Use the Scikit-learn API \texttt{xgboost.XGBClassifier}.
For an initial choice of hyperparameters use 100 trees (\texttt{n_estimators}), maximum tree depth (\texttt{max_depth}) of 10, learning rate (\texttt{learning_rate}) of 0.1, \texttt{colsample_bytree} of 0.8, and \texttt{subsample} of 0.8.

Plot the receiver operating characteristic (ROC) curve using the testing dataset.
What area under the curve (AUC) and accuracy do you achieve ``out of the box''?
\end{problem}


\begin{problem}[5]
Plot the $F$-score for all the 10 ``most important'' features using \texttt{xgboost.plot_importance}.
Which feature is the most important?

Plot this feature using the testing dataset in a 1D histogram separately for signal and background.
For the histogram binning, use 100 bins from the minimum value of this feature to the maximum value of this feature in the testing dataset.
What do you notice about this feature?
\end{problem}


\begin{problem}[15]
Using the MiniBooNE dataset and the Keras Model API, train a neural network with 3 hidden layers each with 128 units and $\tanh$ activations.
The final layer should have sigmoid activation.
Use the binary crossentropy loss function, the SGD optimizer with a learning rate of 0.01 (which is the default), and a batch size of 128.
Train the model for 50 epochs.

Plot the receiver operating characteristic (ROC) curve using the testing dataset.
What AUC and accuracy do you achieve ``out of the box''?
\end{problem}


\begin{problem}[5]
Swap out the $\tanh$ activations for ReLU activations, while keeping everything else the same.
Does the network train effectively?
Why or why not?
\end{problem}

\begin{problem}[5]
Now, we will make two minor changes to the network with ReLU activations: preprocessing and the optimizer.

For the feature preprocessing use \texttt{sklearn.preprocessing.StandardScaler} to standardize the input features.
Note you should fit the standard scaler to the training data \emph{only} and apply it to both the training and testing data.
For the optimizer, use Adam with a learning rate of 0.001 (which is the default) instead of SGD. Train the model for 50 epochs.

Plot the receiver operating characteristic (ROC) curve using the testing dataset.
What AUC and accuracy do you achieve now?
Is it comparable to the BDT?
\end{problem}


\end{document}
